{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecb5c1db",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3687223",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21974350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fd4ff8",
   "metadata": {},
   "source": [
    "#### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ddf10a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data\\IMDB Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ebaf62f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review sentiment\n",
      "0  One of the other reviewers has mentioned that ...  positive\n",
      "1  A wonderful little production. <br /><br />The...  positive\n",
      "2  I thought this was a wonderful way to spend ti...  positive\n",
      "3  Basically there's a family where a little boy ...  negative\n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n"
     ]
    }
   ],
   "source": [
    "# Display first few rows\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ed2458",
   "metadata": {},
   "source": [
    "#### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "94ce05f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     50000 non-null  object\n",
      " 1   sentiment  50000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 781.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Check dataset structure\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9bcf834c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review       0\n",
      "sentiment    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3858fdcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate rows: 418\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicate rows\n",
    "print(f\"Duplicate rows: {df.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e615eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b30f4f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   review sentiment\n",
      "count                                               49582     49582\n",
      "unique                                              49582         2\n",
      "top     Haven't seen the film since first released, bu...  positive\n",
      "freq                                                    1     24884\n"
     ]
    }
   ],
   "source": [
    "# Summary statistics of numerical features\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b354a19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    # Remove special characters and digits\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove extra spaces\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "df['cleaned_review'] = df['review'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3cd879c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review  \\\n",
      "0  One of the other reviewers has mentioned that ...   \n",
      "1  A wonderful little production. <br /><br />The...   \n",
      "2  I thought this was a wonderful way to spend ti...   \n",
      "3  Basically there's a family where a little boy ...   \n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...   \n",
      "\n",
      "                                      cleaned_review  \n",
      "0  one of the other reviewers has mentioned that ...  \n",
      "1  a wonderful little production the filming tech...  \n",
      "2  i thought this was a wonderful way to spend ti...  \n",
      "3  basically theres a family where a little boy j...  \n",
      "4  petter matteis love in the time of money is a ...  \n"
     ]
    }
   ],
   "source": [
    "# Display the first 5 rows of the cleaned dataset\n",
    "print(df[['review', 'cleaned_review']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cdae05e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      cleaned_review  \\\n",
      "0  one of the other reviewers has mentioned that ...   \n",
      "1  a wonderful little production the filming tech...   \n",
      "2  i thought this was a wonderful way to spend ti...   \n",
      "3  basically theres a family where a little boy j...   \n",
      "4  petter matteis love in the time of money is a ...   \n",
      "\n",
      "                                    tokenized_review  \n",
      "0  [one, of, the, other, reviewers, has, mentione...  \n",
      "1  [a, wonderful, little, production, the, filmin...  \n",
      "2  [i, thought, this, was, a, wonderful, way, to,...  \n",
      "3  [basically, theres, a, family, where, a, littl...  \n",
      "4  [petter, matteis, love, in, the, time, of, mon...  \n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Tokenize the reviews\n",
    "df['tokenized_review'] = df['cleaned_review'].apply(word_tokenize)\n",
    "print(df[['cleaned_review', 'tokenized_review']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a7b77629",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    tokenized_review  \\\n",
      "0  [one, of, the, other, reviewers, has, mentione...   \n",
      "1  [a, wonderful, little, production, the, filmin...   \n",
      "2  [i, thought, this, was, a, wonderful, way, to,...   \n",
      "3  [basically, theres, a, family, where, a, littl...   \n",
      "4  [petter, matteis, love, in, the, time, of, mon...   \n",
      "\n",
      "                         cleaned_review_no_stopwords  \n",
      "0  [one, reviewers, mentioned, watching, oz, epis...  \n",
      "1  [wonderful, little, production, filming, techn...  \n",
      "2  [thought, wonderful, way, spend, time, hot, su...  \n",
      "3  [basically, theres, family, little, boy, jake,...  \n",
      "4  [petter, matteis, love, time, money, visually,...  \n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "# Download the stopwords if you haven't already\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Set of stopwords in English\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Remove stopwords\n",
    "df['cleaned_review_no_stopwords'] = df['tokenized_review'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "\n",
    "# Check the cleaned review without stopwords\n",
    "print(df[['tokenized_review', 'cleaned_review_no_stopwords']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6d4d9baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         cleaned_review_no_stopwords  \\\n",
      "0  [one, reviewers, mentioned, watching, oz, epis...   \n",
      "1  [wonderful, little, production, filming, techn...   \n",
      "2  [thought, wonderful, way, spend, time, hot, su...   \n",
      "3  [basically, theres, family, little, boy, jake,...   \n",
      "4  [petter, matteis, love, time, money, visually,...   \n",
      "\n",
      "                                   lemmatized_review  \n",
      "0  [one, reviewer, mentioned, watching, oz, episo...  \n",
      "1  [wonderful, little, production, filming, techn...  \n",
      "2  [thought, wonderful, way, spend, time, hot, su...  \n",
      "3  [basically, there, family, little, boy, jake, ...  \n",
      "4  [petter, matteis, love, time, money, visually,...  \n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download wordnet for lemmatization if you haven't already\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Lemmatize the cleaned review without stopwords\n",
    "df['lemmatized_review'] = df['cleaned_review_no_stopwords'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
    "\n",
    "# Check the lemmatized reviews\n",
    "print(df[['cleaned_review_no_stopwords', 'lemmatized_review']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fce6ae6",
   "metadata": {},
   "source": [
    "#### Feature Eng & Splitting & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6a83052d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.83      0.84      4939\n",
      "    positive       0.84      0.84      0.84      4978\n",
      "\n",
      "    accuracy                           0.84      9917\n",
      "   macro avg       0.84      0.84      0.84      9917\n",
      "weighted avg       0.84      0.84      0.84      9917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle\n",
    "\n",
    "# Use the lemmatized reviews (converted back to string) if you have them\n",
    "X = df['lemmatized_review'].apply(lambda x: ' '.join(x))  # Join lemmatized tokens\n",
    "y = df['sentiment']  # Target labels\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# TF-IDF vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Train Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict and print classification report\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Save model and vectorizer (use binary mode)\n",
    "with open('random_forest_model.pkl', 'wb') as model_file:\n",
    "    pickle.dump(model, model_file)\n",
    "\n",
    "with open('tfidf_vectorizer.pkl', 'wb') as vectorizer_file:\n",
    "    pickle.dump(vectorizer, vectorizer_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "30d58e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Sentiment: positive\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model and vectorizer\n",
    "with open('random_forest_model.pkl', 'rb') as model_file:\n",
    "    model = pickle.load(model_file)\n",
    "\n",
    "with open('tfidf_vectorizer.pkl', 'rb') as vectorizer_file:\n",
    "    vectorizer = pickle.load(vectorizer_file)\n",
    "\n",
    "# Sample input for prediction\n",
    "sample_review = [\"I absolutely loved this movie! The acting was fantastic, and the storyline was so heartwarming.\"]\n",
    "\n",
    "# Transform the sample review using the loaded vectorizer (ensure it's in the same format as training data)\n",
    "sample_review_tfidf = vectorizer.transform(sample_review)\n",
    "\n",
    "# Predict the sentiment using the trained model\n",
    "predicted_sentiment = model.predict(sample_review_tfidf)\n",
    "\n",
    "# Output the prediction\n",
    "print(\"Predicted Sentiment:\", predicted_sentiment[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d5e576ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model and vectorizer saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Sample training data\n",
    "texts = [\n",
    "    \"I loved the movie, it was amazing!\",\n",
    "    \"What a great experience, really enjoyed it!\",\n",
    "    \"Horrible film, I hated it.\",\n",
    "    \"Worst movie ever. Waste of time.\",\n",
    "    \"Absolutely fantastic!\",\n",
    "    \"Not good. Very boring.\",\n",
    "    \"Wonderful plot and great acting.\",\n",
    "    \"Terrible movie with a stupid story.\"\n",
    "]\n",
    "\n",
    "labels = [\n",
    "    \"positive\", \"positive\", \"negative\", \"negative\",\n",
    "    \"positive\", \"negative\", \"positive\", \"negative\"\n",
    "]\n",
    "\n",
    "# Vectorize text\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(texts)\n",
    "\n",
    "# Train model\n",
    "model = LogisticRegression()\n",
    "model.fit(X, labels)\n",
    "\n",
    "# Save vectorizer and model\n",
    "with open(\"D:/Sentimental_Analysis/vectorizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(vectorizer, f)\n",
    "\n",
    "with open(\"D:/Sentimental_Analysis/model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "print(\"✅ Model and vectorizer saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
